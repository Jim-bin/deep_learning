# 三层神经网络：一个输入层，一个隐藏层，一个输出层

## $x^{(1)}$

$$x^{(1)} = {
    \begin{pmatrix}
      x^{(1)}_{1}\\
      x^{(1)}_{2} \\
      ...\\
      x^{(1)}_{j}\\
      ...\\
      x^{(1)}_{n1}
    \end{pmatrix}
  }_{n1×1}$$

## $X$

$$X={
    \begin{pmatrix}
      x^{(1)}_{1} & x^{(2)}_{1} &...& x^{(i)}_{1} &...& x^{(m)}_{1} & \\
      x^{(1)}_{2} & x^{(2)}_{2} &...& x^{(i)}_{2} &...& x^{(m)}_{2} & \\
      ...&...&...&...&...&...\\
      x^{(1)}_{j} & x^{(2)}_{j} &...& x^{(i)}_{j} &...& x^{(m)}_{j} & \\
      ...&...&...&...&...&...\\
      x^{(1)}_{n1} & x^{(2)}_{n1} &...& x^{(i)}_{n1} &...& x^{(m)}_{n1} & \\
    \end{pmatrix}
  }_{n1×m}$$

## $y^{(1)}$

$$y^{(1)}={y^{(1)}}$$

## $Y$

$$Y={
    \begin{pmatrix}
      y^{(1)} & y^{(2)} &...& y^{(i)} &...& y^{(m)} \\
    \end{pmatrix}
  }_{1×m}$$

## $W^{(1)}$

$$W = {
    \begin{pmatrix}
      W^{(1)}_{1,1} & W^{(1)}_{2,1} & ... & W^{(1)}_{j,1} &...& W^{(1)}_{n2,1} &  \\
      W^{(1)}_{1,2} & W^{(1)}_{2,2} & ... & W^{(1)}_{j,2} &...& W^{(1)}_{n2,2} &  \\
      ...\\
      W^{(1)}_{1,i} & W^{(1)}_{2,i} & ... & W^{(1)}_{j,i} &...& W^{(1)}_{n2,i} &  \\
      ...\\
      W^{(1)}_{1,n1} & W^{(1)}_{2,n1} & ... & W^{(1)}_{j,n1} &...& W^{(1)}_{n2,n1} &  \\
    \end{pmatrix}
  }_{n1×n2}$$

## $z^{(1)}$

$$z^{(1)} = (W^{(1)}){^T}x^{(1)}\\
=\begin{pmatrix}
  W^{(1)}_{1,1}x^{(1)}_{1} + W^{(1)}_{1,2}x^{(1)}_{2} + ... + W^{(1)}_{1,n1}x^{(1)}_{n1}  \\

  W^{(1)}_{2,1}x^{(1)}_{1} + W^{(1)}_{2,2}x^{(1)}_{2} + ... + W^{(1)}_{2,n1}x^{(1)}_{n1}  \\
  .......................................................\\
  W^{(1)}_{n2,1}x^{(1)}_{1} + W^{(1)}_{n2,2}x^{(1)}_{2} + ... + W^{(1)}_{n2,n1}x^{(1)}_{n1}  \\
\end{pmatrix}$$

## $Z^{(1)}$

Forward Propagation:
- You get X
- You compute $A = \sigma(w^T X + b) = (a^{(0)}, a^{(1)}, ..., a^{(m-1)}, a^{(m)})$
- You calculate the cost function: $J = -\frac{1}{m}\sum_{i=1}^{m}y^{(i)}\log(a^{(i)})+(1-y^{(i)})\log(1-a^{(i)})$